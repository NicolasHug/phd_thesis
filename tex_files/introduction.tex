\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction} % To add to TOC
\initial{A}nalogical reasoning is widely recognized as a powerful ability of
human intelligence.  It can lead to potential conclusions for new situations by
establishing links between apparently unrelated domains. One well-known example
is the Rutherford-Bohr model of atom where electrons circle around the kernel,
which was analogically inspired by the model of planets running around the sun.
Unsurprisingly, this kind of reasoning has generated a lot of attention from
the artificial intelligence community.

In this work we will focus on a particular model of analogical reasoning,
based on \textbf{analogical proportions}. An analogical proportion is a
statement of the form \textit{a is to b as c is to d}, and expresses the fact
$a$ differs from $b$ in the same manner as $c$ differs from $d$. For example,
one could say that \textit{France is to Paris as Germany is to Berlin}, or that
\textit{electrons are to the kernel as planets are to the sun}. In some cases,
when the element $d$ of the proportion is not known\footnote{Or any other
element, actually.}, it can be \textbf{inferred} from the three other elements
$a, b, c$. It seems indeed natural that even a child with basic geographic
knowledge could answer the question \textit{France is to Paris as Germany is to
what?} with the correct answer: \textit{Berlin}. And even in the event that our
subject does not know that the name of the correct answer is \textit{Berlin},
they could still \textbf{imagine} a city  which is the capital of Germany, and
suppose that this hypothetical city corresponds to the correct answer. We
witness here two key cognitive processes that can be triggered using analogical
proportions: \textbf{inference}, and \textbf{creativity}.

As a tool that allows inductive inference, analogical reasoning has been
proposed for plausible reasoning and for machine learning purposes. Indeed,
analogical proportion-based learning has been addressed in recent works: we may
cite for instance \cite{StrYvoCNLL05} for an application in linguistics (verb
conjugation task), and \cite{BayMicDelIJCAI07} for classification problems in a
Boolean setting. Our investigations follow on from these two works, and the
goal of this thesis is twofold. The first topic is to \textbf{apply analogical
reasoning to real-world problems}, and the second one is to \textbf{exhibit
some theoretical properties of analogical classifiers}.


The application of analogical reasoning to concrete tasks is motivated by the
fact that the previous empirical investigations were only led in standard
artificial settings. To our knowledge, the analogical learners were still to be
experienced in real-world problems to assess their suitability in concrete
applications, where the requirements for success are often significantly
different. We have chosen here to apply analogical learning to the field of
recommender systems.

Also, our theoretical investigations are motivated by the fact that so far,
analogical classifiers were only known from their algorithmic descriptions.  In
fact, each implemented classifier provides a clean description of {\it how to
compute}, but we definitely miss a clean description of {\it what do we
actually compute}. The previous experimental investigations were not directed
to provide an analytical view, and as a result analogical classifiers were yet
quite poorly understood: we had no clear knowledge about their strengths and
weaknesses.

\paragraph{Road map and contributions\\}

Chronologically, we first focused on the applicative side. Our first
contributions were indeed devoted to applying analogical reasoning to the task
of recommendation. Later, we led our theoretical investigations on
analogical classification.

In this document, we will choose to present our work somehow differently.
After having recalled the necessary background on analogical proportions in
Chapters \ref{CHAP:computational_models_of_analogical_reasoning} and
\ref{CHAP:formal_analogical_proportions}, we
will present some of our
theoretical results in Chapter \ref{CHAP:functional_definition}. Then, we will
fully describe our contributions to analogical recommendation  in Chapters
\ref{CHAP:background_reco_systems} and \ref{CHAP:analogical_recommendation},
and finally we will address more theoretical considerations in Chapter
\ref{CHAP:analogy_preserving_functions}. Simply put, our contributions to the
theoretical side will be split up by the topic of analogical recommendation.

This choice is in fact motivated by pedagogical reasons. It will
indeed become clear that the topic of analogical recommendation (Chapters
\ref{CHAP:background_reco_systems} and \ref{CHAP:analogical_recommendation}) is
a lot easier to introduce and to understand once we have enough background on
analogical classification (Chapter
\ref{CHAP:functional_definition}), as our methods for analogical recommendation
are strongly inspired by previous works on analogical classification. Moreover,
whereas the motivations for Chapter \ref{CHAP:analogy_preserving_functions}
could have been directly derived from the results of Chapter
\ref{CHAP:functional_definition}, it will be more interesting to account for
Chapter \ref{CHAP:analogy_preserving_functions} in the light of the results of
Chapter \ref{CHAP:analogical_recommendation}.

We now provide the detailed structure of this document.\\

The first chapter will provide the necessary background on existing
models of analogical reasoning, with a strong emphasis on models that allow to
perform computational inference. It will appear that these models are, for the
most part, motivated by cognitive and psychological aspects, and depart from
our main computational tool: formal analogical proportions.\\

Formal analogical proportions are the subject of the second chapter. We will
provide their definitions in various algebraic settings,
focusing on the two proportions that we will mostly use: the arithmetic
proportion (dealing with real numbers), and the Boolean proportion. In
addition, we will try to give a geometrical insight on these two proportions,
which to the best of our knowledge had never been
done before. We will also go through a toy classification problem that will
allow us to describe the process of \textbf{analogical equation
solving}\footnote{Very roughly, analogical equation solving is the process of
finding the unknown $x$ in the proportion \textit{$a$ is to $b$ as $c$ is to
$x$}, e.g. \textit{France is to Paris as Germany is to What?}}, and the
\textbf{analogical inference principle} that underlies all
of our investigations. In a classification context, this
principle states that if $a$ is to $b$ as $c$ is to $d$,
then we should also have that $f(a)$ is to $f(b)$ as $f(c)$ is to $f(d)$, where
$f(x)$ is the function that determines the class of $x$. It is obviously an
unsound inference principle, in that the conclusion does not follow from the
premise. But as we will see, it can still be used for classification tasks,
which is the subject of the third chapter.\\

The study of analogical classification is indeed the object of Chapter
\ref{CHAP:functional_definition}, which corresponds to a detailed version of our
ECAI paper: \cite{HugPraRicSerECAI16}. In this chapter, we will start to
address one of the two main objectives of this thesis: identifying theoretical
properties of analogical classifiers. Our first contribution will be to provide
a functional definition of analogical classifiers, that will unify the two
pre-existing approaches mentioned earlier (\cite{StrYvoCNLL05} and
\cite{BayMicDelIJCAI07}). This new definition will bring more
insight into these classifiers, enabling us to derive results related to their
VC-dimension, as well as their error rate. Our functional definition will also
reveal the close links between the analogical classifiers and the $k$-nearest
neighbors ($k$-NN) techniques. We will show indeed that the analogical
classification process can be viewed as a two-step procedure that first
consists in extending the training
set (by \textbf{generating} new examples), and then applying a $k$-NN
classifier. Quite remarkably, the two key cognitive processes related to
analogical proportions (inference and creativity),
are here blended together. From these results, a natural question arises: how
can we ensure a training set extension that is completely error-free? This
question will be addressed later in Chapter
\ref{CHAP:analogy_preserving_functions}, while the  following two chapters
(\ref{CHAP:background_reco_systems} and \ref{CHAP:analogical_recommendation})
will be devoted to our second main objective: applying analogical reasoning to
the task of recommendation.\\

Chapter \ref{CHAP:background_reco_systems} will be dedicated to the necessary
background on recommender systems. We will briefly review the three main
families of recommender systems, namely content-based techniques, collaborative
filtering, and knowledge-based systems. We will also formally define the
problem that we plan to address, which is that of rating prediction: given a
database of  user-item interactions taking the form of ratings, the goal is to
predict all the ratings for the pairs (user, item) that are not in the
database. The different measures allowing to assess the quality of the
predictions will be presented. Finally, as our contributions will be of a
collaborative nature, we will thoroughly detail two popular methods for
collaborative filtering: the neighborhood-based techniques, and the
matrix-factorization-based methods. These two families of algorithms will serve
as benchmarks to compare the performance of our own algorithms.\\

In Chapter \ref{CHAP:analogical_recommendation}, we will present our
contributions to the topic of recommender systems. We will first describe our
preliminarily investigations, which are a direct adaptation of the analogical
classifier described in the previous chapter. These first investigations were
the object of a paper published at ISMIS \cite{HugPraRicISMIS15}. It will
become clear that while offering similar accuracy to the traditional
approaches, analogical recommenders suffer from their cubic complexity.
Acknowledging this fact, we developed another view of analogical
recommendation, taking into account the fact that some users may have different
interpretation of the rating scale. The algorithms that we derived were much
more scalable than the previous ones, and these investigations where described
in a Fuzz-IEEE paper \cite{HugPraRicSerFuzzIEEE16}.  Finally, we will address
the problem of mining analogical proportions between users (or items) in a
rating database \cite{HugPraRicSerLFA16}. Our results will help us to
retrospectively interpret the modest performances of our analogical
recommenders: as bland as it may seem, it turns out that there were just not
enough decent analogies to be found in the available databases.\\

But this down-to-earth observation will lead us to the very questioning of
the analogical inference principle that had been underlying all of our
investigations so far. In the last chapter, we will go back to our theoretical
considerations, and provide a criterion that allows us to apply analogical
inference in a sound way. We have briefly described that the analogical
inference principle states that if four elements $a, b, c, d$ are in
proportion, then their classes $f(a), f(b), f(c), f(d)$ should also be in
proportion. We will provide a complete characterization of the functions $f$
such that when four elements are in proportion, then their image by $f$ are
also in proportion: these functions ensure a safe use of the analogical
inference principle. It will be clear that these functions are also the ones
that allow to extend a training set by analogy in a perfectly safe way. We will
call these functions the \textbf{analogy preserving} functions, and they will
turn out to be the well-known affine functions, both in Boolean and real
settings. These investigations led to an IJCAI paper
\cite{CouHugPraRicIJCAI17}, and provide various future research tracks.\\


We will now start with the first chapter, dedicated to the description of
previous (and current) attempts at formalizing analogical reasoning.
