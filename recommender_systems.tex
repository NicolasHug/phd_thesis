\chapter{Recommender systems}

In a world of information overload, automatic filtering tools are essential to
extract relevant information from basic noise. In the field of e-commerce,
recommender systems play the role of search engines when surfing the entire
web: they filter available items to provide relevant suggestions to customers.

With the huge development of online businesses, recommender systems have become
more and more popular \cite{RecoSystemHandbook,AdoTuzIEEE2005}. They help to
answer questions as diverse as ``what movie to rent?", ``what item to buy?" or
``which restaurant to try?", but also such as ``what piece of code to
investigate ?" in the case of recommender system for software development.
They do so by providing the user with a list of recommendations.  Obviously,
the more personalized the recommendations, the better the system.  For
instance, a system recommending only the most popular items is useless as it is
likely that the standard customer knows these items. But the maximization of
business profit may also lead to suggest items which are not very popular (and
thus difficult to sell), provided they may be of interest for the user.

A very common way of providing personalized recommendations to a target user is
to estimate its taste for the items that the system provides. The taste of a user
$u$ for a given item $i$ is usually represented as a rating that $u$ would give
to $i$.  The scale of the ratings may vary, but the integer interval [1, 5] and
the \textit{like}/\textit{dislike} scales are very common in real world
systems.

Once these estimations are made, a simple option is to recommend the items with
the highest ratings among all the estimated scores for the considered user
(using the implicit assumption that a user should be interested in the items
with high scores).

Providing an accurate measure of the overall quality of a recommender system is
not a simple task and diverse viewpoints have to be considered (see
\cite{RecoSystemHandbook} for an extensive survey).  Obviously, accuracy of
its core prediction algorithm is an important matter, but other properties are
also desirable in order  to deploy an effective recommendation engine. For
instance {\it coverage} measuring what is the range of items in the catalogue
that could be recommended, or {\it serendipity} measuring in some sense the
surprise that a user could get when a new item is suggested.

\section{Background on recommender systems}\label{backReco}
The aim of a recommendation system is to provide users with lists of relevant
personalized items.
Let us now formalize the problem.

\subsection{Problem formalization}
Let $U$ be a set of users and $I$ a set of items. For some pairs $(u,i) \in U
\times I$, a rating  $r_{ui}$ is supposed to have been given by $u$ to express
whether she likes the item $i$ or not. 
It is quite common that  $r_{ui} \in [1, 5]$, 5 meaning a strong preference for
item $i$, 1 meaning a strong rejection, and 3 meaning indifference, or just an
average note.  Let us denote by $R$ the set of ratings recorded in the system. It
is well known that, in real systems, the size of $R$ is very small with regard
to the potential number of ratings which is $|U| \times |I|$, as a lot of
ratings are missing. In the following, $U_i$ denotes the set of users that have
rated item $i$, and $I_u$ is the set of items that
user $u$ has rated. 

To recommend items to users, a recommender system will proceed as follows:
\begin{enumerate}
\item Using a prediction algorithm $A$, estimate the unknown ratings $r_{ui}$
(i.e. $r_{ui} \notin R$). This estimation $A(u, i)$ is usually denoted
$\hat{r}_{ui}$.  
\item Using a recommendation strategy $S$ and in the light of the previously
estimated ratings, recommend items to users. For instance, a basic yet
common strategy is to suggest to user $u$ the items $i \notin I_u$ with the
highest $\hat{r}_{ui}$.
\end{enumerate}
The two main prediction techniques are commonly referred to as {\it
content-based} and {\it collaborative filtering}, that we both briefly review
below.

%depending on the techniques
%deployed by their prediction algorithm $A$. Hybrid methods actually are a mix
%of collaborative and content-based techniques. We will here give a short
%overview of content-based and collaborative filtering techniques, without
%lingering too much over current content-based ones as they have shown to be
%outperformed by collaborative techniques.

\subsection{Content-based techniques}

Content-based algorithms use the metadata of users and items to estimate a
rating. Metadata are external information that can be collected. Typically:
\begin{itemize}
\item  for users: gender, age, occupation, location (zip code), etc.
\item for items: it depends on the type of items, but in the case of movies, it
could be their genre, main actors, film director, etc.  \end{itemize}
 
Based on these metadata, a content-based system will try to find items that are
similar to the ones for which the target user has already expressed a
preference (for instance by giving a high rating). This implies the need for a
similarity measure between items.  A lot of options are available for such
metrics. They will not be discussed here as our method is of a collaborative
nature. 

Indeed, a well-known drawback of content-based techniques is their tendency to
recommend only items that users may already know, and therefore the
recommendations lack in novelty, surprise and diversity. In the following, we
only use collaborative filtering techniques, so we do not consider the use of
any metadata.

\subsection{Collaborative filtering techniques}
\label{CollabFil}
By collaborative filtering, we mean here algorithms that only rely on the set
of known ratings $R$ to make a prediction: to predict $r_{ui} \notin R$, the
algorithm $A$ will output $\hat{r}_{ui}$ based on $R$ or on a carefully chosen
subset.  The main difference between collaborative and content-based method is
that in the former, metadata of items and users are not used, and in the latter
the only ratings we may take into account are that of the target user.  A
popular collaborative filtering technique is neighbourhood-based, that we
describe here in its simplest form.

%The neighbourhood-based approaches have proven
%to be fairly accurate. 
To estimate the rating of a user $u$ for an item $i$, we
select $N_i^k(u)$, the set of $k$ users that are most similar to $u$ and that
have rated $i$. Here again, there is a need for a similarity measure (between
users, and based on their respective ratings). The estimation of $r_{ui}$ is computed as follows:
$$\hat{r}_{ui} = \aggr{v \in N_i^k(u)}r_{vi},$$
where the aggregate function $\aggr{}$ is usually a mean weighted by the similarity between $u$
and $v$. A more sophisticated prediction, popularized by
\cite{BelKorSIGKDD2007} is as follows:
$$\hat{r}_{ui} = b_{ui} + \aggr{v \in N_i^k(u)}(r_{vi} - b_{vi}),$$
where $b_{ui}$ is a baseline (or bias) related to user $u$ and item $i$. It
is supposed to model how $u$ tends to give higher (or lower) ratings than the
average of ratings $\mu$, as well as how $i$ tends to be rated higher or lower
than $\mu$. As it uses the neighbourhood of users to output a prediction, this
technique tends to model local relationships in the data.

Note that it is perfectly possible to proceed in an item-based way. Indeed,
rather than looking for users similar to $u$, one may look for items similar to
$i$, which leads to formulas dual of the above ones. 

The matrix factorization approach is heavily inspired by singular value
decomposition (SVD): it postulates the existence of $f$ factors/criterias
(whose nature is not necessarily known) that determine the value of any rating
$r_{ui}$.  A user $u$ is modeled as a vector $p_u \in \mathbb{R}^f$, where each
component of $p_u$ models the importance of the corresponding factor for $u$.
Similarly, an item $i$ is modeled as a vector $q_i \in \mathbb{R}^f$, where
each component of $q_i$ models how well $i$ fits the corresponding criteria.
From then, a rating prediction $\hat{r}_{ui}$ is calculated as the dot product
of the two vectors $p_u$ and $q_i$: $$\hat{r}_{ui} = p_u^t \cdot q_i$$ For the
interested reader, see the work of
\cite{Funk2006,KorACM2010} The number of factors being set,
the problem is here to estimate the vectors $p_u$ and $q_i$ for every possible
users and items. Two methods are commonly used for this task: alternating least
squares and stochastic gradient descent, first popularized by \cite{Funk2006}.

Contrary to the neighbourhood-based approach, the matrix factorization
technique tends to model global aspects of the data.  Matrix factorization and
neighbourhood based techniques have been successfully mixed in the works of
\cite{KorACM2010}.  


\subsection{Recommender system
evaluation}\label{eval} Providing an accurate measure of the overall quality of
a recommender system is not a simple task and diverse viewpoints have to be
considered (see \cite{RecoSystemHandbook} for an extensive survey). 
% Obviously
%accuracy is an important matter as  any system includes a prediction algorithm,
%but other properties are also desirable in order  to deploy an effective
%recommendation engine.



\paragraph{Accuracy\\}
The performance of the algorithm $A$ is usually evaluated in terms of accuracy,
which measures how close the rating prediction $\hat{r}_{ui}$ is to the true
rating value $r_{ui}$, for every possible prediction. To evaluate the accuracy
of a prediction algorithm, one usually follows the classical machine learning
framework: the set of ratings $R$ is divided into two disjoint sets $R_{train}$
and $R_{test}$, and the algorithm $A$ has to predict ratings in $R_{test}$
based on the ones belonging to $R_{train}$.

The Root Mean Squared Error (RMSE) is a very common indicator of how accurate
an algorithm is, and is calculated as follows:
$$\text{RMSE}(A) = \sqrt{\frac{1}{|R_{test}|}\sum_{r_{ui} \in
R_{test}}(\hat{r}_{ui} - r_{ui})^2}$$
%Another common indicator for accuracy is the Mean Absolute Error (MAE), where
%important errors are not penalized more than small ones:
%$$\text{MAE}(A) = \frac{1}{|R_{test}|}\sum_{r_{ui} \in R_{test}}|\hat{r}_{ui} -
%r_{ui}|.$$

To better reflect the user-system interaction, other precision-oriented metrics
are generally used in order to provide a more informed view.

\paragraph{Precision and recall\\}
Precision and recall help measuring the ability of a system to provide
relevant recommendations.
In the following, we denote by $I_{S}$ the set of items that the strategy
$S$ will suggest to the users using the predictions coming from $A$. For
ratings in the interval $[1, 5]$, a simple strategy could be for example to
recommend an item $i$ to user $u$ if the estimation rating $\hat{r}_{ui}$ is
greater than $4$.  $$I_S = \{i \in I | \exists u \in U, \hat{r}_{ui} \geq
4\}.$$

Let $I_{relev}$ be the set of items that are actually relevant to users (i.e.
the set of items that would have been recommended to users if all the
predictions made by $A$ were exact). 
The precision of the system is defined as the fraction of recommended items that
are relevant to the users:
$$\text{Precision} = \frac{|I_{S} \cap I_{relev}|}{|I_{S}|},$$
and the recall as the fraction of recommended items that are relevant to the
users out of all possible relevant items:
$$\text{Recall} = \frac{|I_{S} \cap I_{relev}|}{|I_{relev}|},$$

If accurate predictions are crucial, it is widely agreed that it is
insufficient for deploying an effective recommendation engine. Indeed, still
other dimensions are worth estimating in order to get a complete picture of the
performance of a system.
\cite{NeeRieKonACM2006,HerKonJohTerRieACM2004,KamBriRecSys2014}.
For instance, one may naturally expect from a recommender system
not only to be accurate, but also to be surprising, and to be able to recommend
a large number of items. When evaluating the recommendation strategy, one must
keep in mind that its performance is closely related to that of the algorithm
$A$, as the recommendation strategy $S$ is based on the predictions provided by
$A$.


\paragraph{Coverage\\}
Coverage, in its simplest form, is used to measure the ability of a system to
recommend a large amount of items: it is quite easy indeed to create a
recommender system that would only recommend very popular items. Such a
recommender system would drop to zero added value. Coverage can be defined as the
proportion of recommended items out of all existing items:
$$\text{Coverage} = \frac{|I_{S}|}{|I|}.$$



\paragraph{Surprise\\}
Users expect a recommender system to be surprising: recommending an extremely
popular item is not really helpful. Following the works of \cite{KamBriRecSys2014}, surprise of a recommendation can be evaluated with the help of the pointwise mutual
information (PMI). The PMI between two items $i$ and $j$ is defined as follows:
$$PMI(i, j) = -\log_2 \frac{p(i, j)}{p(i)p(j)} / \log_2 p(i, j),$$
where $p(i)$ and $p(j)$  represent the probabilities for the items to be rated
by any user, and $p(i, j)$ is the probability for $i$ and $j$ to be rated
together: $p(i) = \tfrac{|U_i|}{|U|}$ and $p(i, j) = \tfrac{|U_i \cup
U_j|}{|U|}$. PMI values fluctuate between the interval $[-1, 1]$, $-1$ meaning
that $i$ and $j$ are never rated together and $1$ meaning that they are always
rated together. To estimate the surprise of recommending an item $i$ to a user
$u$ we have two choices: 
\begin{itemize}
\item either to take the maximum of the PMI values for $i$ and all
other items rated by $u$, with $Surp^{max}(u, i) = \max\limits_{j\in I_u} PMI(i, j)$
\item
 or to take the mean of these PMI values with $Surp^{avg}(u, i) =
\frac{\sum_{j \in I_u} PMI(i, j)}{|I_u|}$
\end{itemize}
Then the overall capacity of a recommender to surprise its users is the mean of the
surprise values for all predictions.
